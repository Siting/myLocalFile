\section{Problem 3: High Speed Routers}

\subsection{part 1}

\begin{enumerate}
\item Each forwarding engine has a complete set of the routing tables. Traditionally, routers keep a central master routing table and the satellite processors each keep only several latest used routes. If a route information is not available in the satellite processors, they request the information from the central master routing table. Therefore, at high speeds, the cost of requesting routing table multiple times is much higher than processing the packet header. By letting each forwarding engine has a complete set of routing tables would overcome the bottleneck issue.
\item The MGR uses a switched backplane. Switched backplane allows parallelism of a switch compared to the traditionally applied shared bus mechanism.
\item The MGR includes Quality of Service (QoS) processing in the router by splitting the QoS function. The forwarding engine classifies packets and a specialized processor called QoS processor takes charge of the scheduling of the packets. This design proves the possibility of building a router that includes line-speed QoS.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{part 2}

\subsubsection{part a}
The Ethernet-used ARP does not work for the MGR architecture is because the pipelined MGR does not have a convenient place in the forwarding engine to store datagrams awaiting an ARP reply.

\subsubsection{part b}
The ARP is implemented following a two-part strategy. The first part is the router ARP's for all possible addresses on each interface to collect link-layer addresses for the forwarding tables at a low frequency. And the second part is datagrams for which the destination link-layer address is unknown are passed to the network processor, which does the ARP and, once it gets the ARP reply, forwards the datagram and incorporates the link-layer address into future forwarding tables.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{part 3}
\subsubsection{part a}
The reason IP header checksum is not checked is due to its high cost. In the best situation, it would require 17 instructions to be spread over a minimum of 14 cycles which increase the time to perform the forwarding code about 21\%. It is considered as high cost to check for a rare error that can be caught end-to-end.

\subsubsection{part b}
\begin{enumerate}
\item If the destination in a header of a data packet is missed in the route cache, the packet will not be handled in fast path code which could result in reordered packets.
\item Since the forwarding engine is designed to instruct the inbound line card to discard the errored packets, therefore packets whose headers have errors will be discarded and appear as lost.
\item For datagrams whose headers has IP options, and the datagrams that must be fragamented, they are sent to the network processor for further processing which could results in reordered packets.
\item To deal with multicast datagrams, the processor needs to write out copies of the header in order to dispatch copies of the datagram. The routing process is done by multicasting code which could also leads to delay and packet reordering.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{part 4}
The advantage of switched architecture is it does not have the problem of head-of-line blocking since each input keeps its own FIFO and bids separately for each output. And it was shown that such a switch can achieve 100\% throughput.

The disadvantage of switched architecture is that it is a point-to-point switch without the function of one-to-many, so it does not support multi-casting.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{part 5}

One option is as described in the "A 50-Gb/s IP Router" paper. Split the forwarding table memory on forwarding engines into two parts, call them A and B. When getting the latest forwarding table from network processor, only one or the two memories is used. Let's assume the updated information is feeding in to part A. At the same time, part B is still being used by forwarding engines to forward packets. As soon as the complete forwarding information finished updating in part A, forwarding engines start to use the forwarding information from A. Therefore, in the described process, there is no time that is spent on updating forwarding table solely. In other words, while updating the forwarding table, packets are still being sent by forwarding engines which makes the updating process seems as no designated time is required.

Another option is in the situation when bandwidth is a high limitation which means updating forwarding table for all forwarding engines would cause congestion in the network. Furthermore, it would slow down the updating process for all forwarding engines. Therefore, we could divide the network into different zones and let each zone has a master forwarding engine. When forwarding information needed to be pushed from network processor to forwarding engines, the forwarding engines will feed the forwarding table to those master forwarding engines. After the table in master forwarding engines got updated, they will push the table to other forwarding engines in their zones respectively.








